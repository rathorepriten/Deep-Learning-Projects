{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e42a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Requirement 'imageai-2.0.2-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing ./imageai-2.0.2-py3-none-any.whl\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/Users/rathorepriten/Desktop/DL_projs/imageai-2.0.2-py3-none-any.whl'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.13.1 (from versions: 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.13.1\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras==2.3.0 in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (from keras==2.3.0) (2.0.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (from keras==2.3.0) (1.15.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (from keras==2.3.0) (1.17.0)\n",
      "Requirement already satisfied: pyyaml in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (from keras==2.3.0) (6.0.2)\n",
      "Requirement already satisfied: h5py in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (from keras==2.3.0) (3.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (from keras==2.3.0) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/rathorepriten/miniconda3/envs/myenv/lib/python3.10/site-packages (from keras==2.3.0) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imageai-2.0.2-py3-none-any.whl\n",
    "%pip install tensorflow==1.13.1\n",
    "%pip install keras==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b68a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "detector = ObjectDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9d3fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You are trying to use a Tensorflow model with ImageAI. ImageAI now uses PyTorch as backed as from version 3.0.2 . If you want to use the Tensorflow models or a customly trained '.h5' model, install ImageAI 2.1.6 or earlier. To use the latest Pytorch models, see the documentation in https://imageai.readthedocs.io/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m detector\u001b[38;5;241m.\u001b[39msetModelTypeAsYOLOv3()\n\u001b[1;32m      3\u001b[0m detector\u001b[38;5;241m.\u001b[39msetModelTypeAsTinyYOLOv3()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetModelPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/rathorepriten/Desktop/DL_projs/Yolo Tiny Model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m detector\u001b[38;5;241m.\u001b[39mloadModel()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/imageai/Detection/__init__.py:206\u001b[0m, in \u001b[0;36mObjectDetection.setModelPath\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m'setModelPath()' function is required and is used to set the file path to the model adopted from the list of the\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03mavailable 3 model types. The model path must correspond to the model type.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param model_path:\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[0;32m--> 206\u001b[0m     \u001b[43mextension_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__model_path \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__model_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/imageai/backend_check/model_extension.py:5\u001b[0m, in \u001b[0;36mextension_check\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextension_check\u001b[39m(file_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to use a Tensorflow model with ImageAI. ImageAI now uses PyTorch as backed as from version 3.0.2 . If you want to use the Tensorflow models or a customly trained \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m model, install ImageAI 2.1.6 or earlier. To use the latest Pytorch models, see the documentation in https://imageai.readthedocs.io/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid model file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please parse in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You are trying to use a Tensorflow model with ImageAI. ImageAI now uses PyTorch as backed as from version 3.0.2 . If you want to use the Tensorflow models or a customly trained '.h5' model, install ImageAI 2.1.6 or earlier. To use the latest Pytorch models, see the documentation in https://imageai.readthedocs.io/"
     ]
    }
   ],
   "source": [
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelTypeAsTinyYOLOv3()\n",
    "detector.setModelPath(\"/Users/rathorepriten/Desktop/DL_projs/Yolo Tiny Model.h5\")\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a14144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gst(no_signals,number): #car bus motorcycle truck\n",
    "    time= [2,1,2.5,2.5]\n",
    "    x=0\n",
    "    for i in range(0,4):\n",
    "        x+=number[i]*time[i]\n",
    "    gst= int (x/(no_signals +1))\n",
    "    print(gst)\n",
    "    return(gst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dddf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "signal=[[0,0,0],[0,0,0],[0,0,0],[0,0,0]]\n",
    "k=0\n",
    "l=[]\n",
    "no_signals = 4\n",
    "with open('/content/image_files.txt') as f:\n",
    "  l = f.read().splitlines() \n",
    "\n",
    "def countdown(t, signal,SN,k,state):\n",
    "    j=5\n",
    "    m=k\n",
    "    s=state\n",
    "    if(s==0):\n",
    "      sys.exit('end')\n",
    "    else:   \n",
    "        while True:\n",
    "            sn=SN\n",
    "            i=t\n",
    "\n",
    "            if(i>5):\n",
    "              mins, secs = divmod(t, 60)\n",
    "              timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "              print(timer, end=\"\\r\")\n",
    "              time.sleep(1)\n",
    "              signal[sn][2]=t\n",
    "              print(signal)\n",
    "              t -= 1\n",
    "              i=t\n",
    "              \n",
    "            \n",
    "            elif(i<=5 and i>0):\n",
    "              \n",
    "              mins, secs = divmod(t, 60)\n",
    "              timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "              print(timer, end=\"\\r\")\n",
    "              time.sleep(1)\n",
    "              signal[sn][2]=t\n",
    "              signal[(sn+1)%(no_signals)][0]=i+5\n",
    "              print(signal)\n",
    "              t -= 1\n",
    "              i=t\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "            elif(i<=0 and j>=0):\n",
    "              \n",
    "              signal[sn][0]=0\n",
    "              signal[sn][2]=0\n",
    "              mins, secs = divmod(j, 60)\n",
    "              timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "              print(timer, end=\"\\r\")\n",
    "              time.sleep(1)\n",
    "              signal[sn][1]=j\n",
    "              signal[(sn+1)%(no_signals)][0]=j\n",
    "              j-=1\n",
    "              print(signal)\n",
    "              \n",
    "            else:\n",
    "          \n",
    "\n",
    "\n",
    "                detections = detector.detectObjectsFromImage(input_image=l[m], output_image_path=\"imagenew.jpg\", minimum_percentage_probability=30)\n",
    "                objects=['car','bus','motorcycle','truck','person']\n",
    "                number=[0,0,0,0,0]\n",
    "                for j in range(0,5):\n",
    "                  for eachObject in detections:\n",
    "                    if(eachObject['name']==objects[j]):\n",
    "                      number[j]=number[j]+1\n",
    "                number[2]= number[2]+number[4]\n",
    "                print(m)\n",
    "                m=m+1\n",
    "                if(m==len(l)):\n",
    "                  print('end')\n",
    "                  s = 0\n",
    "\n",
    "                signal=[[0, 0, 0],  [0, 0, 0],  [0, 0, 0],  [0, 0, 0]]\n",
    "                sn=((sn+1)%(no_signals)) # equivalent to sn=sn+1 initially, but once sn reaches the end, it loops back to first.\n",
    "                gt=gst(no_signals,number)\n",
    "                countdown(gt,signal,sn,m,s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
